# I'm Akshaj

Grad student @ UT Austin. I work on machine learning systems — mostly stuff that makes large language models faster, less memory-hungry, and slightly less cursed to deploy.

Right now I'm deep into efficient transformer inference: KV caching, custom attention mechanisms, benchmarking weird ideas from arXiv. Occasionally implement them. Sometimes they even work.

Open to 2025 roles in ML systems / AI infra / research engineering. 


---

## 🧠 Things I care about:
- ML systems, LLM optimization, fast inference
- Transformers under the hood
- Making models do more with less

---

## 🌐 Reach out
- 📧 [akshaj.murhekar@utexas.edu](mailto:akshaj.murhekar@utexas.edu)
- 🧑‍💼 [LinkedIn](https://www.linkedin.com/in/akshaj-murhekar/)

