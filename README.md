# I'm Akshaj

Grad student @ UT Austin. I work on machine learning systems â€” mostly stuff that makes large language models faster, less memory-hungry, and slightly less cursed to deploy.

Right now I'm deep into efficient transformer inference: KV caching, custom attention mechanisms, benchmarking weird ideas from arXiv. Occasionally implement them. Sometimes they even work.

Open to 2025 roles in ML systems / AI infra / research engineering. 


---

## ğŸ§  Things I care about:
- ML systems, LLM optimization, fast inference
- Transformers under the hood
- Making models do more with less

---

## ğŸŒ Reach out
- ğŸ“§ [akshaj.murhekar@utexas.edu](mailto:akshaj.murhekar@utexas.edu)
- ğŸ§‘â€ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/akshaj-murhekar/)

